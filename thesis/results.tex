\chapter{Results}

\section{Results}

Traffic classification algorithms are evaluated using a number of metrics, the
primary of these being the true positive rate sometimes known as the detection
rate (DR) and the false positive rate. A strong traffic classifier typically
has a high true positive rate and a low false positive rate. In table
\ref{table:results} the true positive rate indicates the percentage of
individual sessions correctly classified as the listed protocol. The false
positive rate indicates the percentage of sessions incorrectly labelled as the
listed protocol. Included with these is the area under the receiver operating
characteristic (ROC) curve. The ROC is a tool used for evaluating the
usefulness and comparing different matching algorithms and is often used to
compare Internet traffic classification techniques
\parencite{citeulike:167557,Nguyen:2008p3837}.

All of the algorithms chosen were able to successfully classify HTTPS and HTTP
over Tor traffic with accuracy in excess of 90\%, with the Adaboost algorithm
unable to classify HTTPS over Tor. The best performing algorithm random forest
was able to classify HTTP over Tor with 93.7\% accuracy and a false positive
rate of 3.7\%. HTTPS over Tor was more easily identified with a 97.7\% accuracy
and low false positive rate of 0.3\%.

\input weka-automated-results.tex

\section{Algorithms Used}

A brief description of the machine learning algorithms utilized as well as the
motivation for their inclusion is described below.

\subsection{Random Forest}

The random forest algorithm is a classifier that builds multiple decision trees
with random sets of features. An input is processed by each tree, and the
classification chosen is the one which is produced by most of the trees
\parencite{Ho:1995vm}. For this experiment, the random forest algorithm
generated 10 trees and used 6 random features.

The random forest algorithm was chosen for its unparalleled accuracy and strong
performance \parencite{Leo-Breiman:2004fk}.

\subsection{j4.8}

j4.8 is a Java version of the C4.5 classification algorithm, which has a
permissive open source license and is available in the Weka software suite. It
builds a decision tree using the concept of information entropy
\parencite{Quinlan:1993:CPM:152181}, creating decision branches for features of
a set of data that display the most uncertainty. This algorithm was chosen
because of it's successful use in earlier traffic classification publications.

\subsection{AdaBoost}

Adaptive Boosting is a technique of combining various weak classifiers to
create a strong classifier \parencite{Schapire:1999uq}, the AdaBoost algorithm.
It has been used successfully in several traffic classification applications
\parencite{Alshammari:2009p7474,Haffner:2005p3822,Mohd:2009p6484} and purports
to not suffer from the problem of over-fitting.

\chapter{Discussion of Results}

\section{Limitations}

The classifiers developed within this experiment have been trained against
a relatively small sample set of simulated data, which may only represent
a small fraction of the width and breadth of conditions available on a wider
area network. The characteristics that allow for classification of Tor network
may be masked by the natural variability introduced by a heterogeneous network.

The real Tor network consists of over two hundred thousand computer systems,
with over two thousand routers \parencite{TorStatus:2011fk}, all with different
operating systems, different hardware, different configurations and available
bandwidth. All the variables that were controlled for during this experiment
are present in the real network, and may be amplified by it's greater size.

Real world traffic may produce completely different statistical properties.
This could simply mean that new features should be selected to create a real
world Tor classifier, or it could mean that there is too much variability
present for modern classification algorithms. The AdaBoost algorithm for
instance, has shown to be defeated by the presence of random noise which would
be more likely in an real environment \parencite{Long:2008ha}.

Without further research it is difficult to say if the technique demonstrated
here will apply in the wild.

\section{Addressing Research Questions}

\subsection{Can Tor traffic be distinguished from other network traffic that
uses similar or the same encryption and protocols?}

Under the controlled conditions of the experiment demonstrated within this
thesis, comparing a sample of simulated encrypted network traffic produced
by a commonly used web browser versus the same traffic routed over a
demonstration Tor network, all the techniques used were able to classify
Tor traffic with a high level of accuracy.

\subsection{Can Tor traffic be identified using automated matching techniques?}

All the classification algorithms trialled were able to successfully classify
web browser traffic routed over the simulated Tor network, with the best
performing algorithm able to correctly classify 95\%.

The value of this level of accuracy depends on the application. A
commercial Internet Service Provider (ISP) or University network may risk
upsetting its users if it were to accidentally block 5\% of regular
encrypted traffic by implementing a firewall that blocked based on this
classifier. Alternatively it could prove useful for identifying systems
running the Tor software. Tor nodes make multiple connections to the
network, both in parallel and over time. Recognizing several Tor streams to
an individual system would provide sufficient confidence to classify it as
a Tor node.

\subsection{Does Tor traffic have characteristics that make it readily
distinguishable using heuristics based matching?}

While each phase of the experiment was conducted over a similar time
period, the number of sessions captured differs greatly. This suggests that
the Tor network may introduce significant overhead to communications
streams. How this latency manifests itself will determine how useful it is
as an identifying characteristic.

Examining all of the data sets, the following set of statistics are obtained:

\begin{table}[H]
  \begin{tabular}{lrrrrrr}
    \toprule
    Phase & Minimum & 1st Quartile & Median & Mean & 3rd Quartile & Max \\
    \midrule
    1 & 66 & 66 & 699 & 860.4 & 1514 & 1514\\
    2 & 66 & 66 & 652 & 760.3 & 1514 & 1514\\
    3 & 66 & 66 & 652 & 733.7 & 1514 & 1514\\
    \bottomrule
  \end{tabular}
  \caption{Summary of packet sizes}
  \label{table:packet_size_statistics}
\end{table}

These statistics don't suggest much, the minimum size and 1st quartile
represent the presence of empty packets typically sent to create and destroy
connections as well as acknowledge received data. The 3rd quartile and maximum
sizes represent the maximum transmission unit for the Ethernet specification
\parencite{Postel:1988fk}. Only the median and mean statistics suggest any
difference, with Tor traffic showing a possible preference for slightly smaller
packets.  Representing each phase as a histogram however, shows a very clear
distinction between regular and Tor traffic.

\begin{figure}[H]
  \centering\includegraphics[width=\linewidth]{https_hist}
  \caption{Histogram of packet size for HTTPS traffic}
  \label{https_hist}
\end{figure}

\begin{figure}[H]
  \centering\includegraphics[width=\linewidth]{http_tor_hist}
  \caption{Histogram of packet size for HTTP traffic over Tor}
  \label{http_tor_hist}
\end{figure}

\begin{figure}[H]
  \centering\includegraphics[width=\linewidth]{https_tor_hist}
  \caption{Histogram of packet size for HTTPS traffic over Tor}
  \label{https_tor_hist}
\end{figure}

In fact, the peaks seen in each graph represent individual packet sizes, the
count for each phase is shown in table \ref{table:packet_size_summary}.

\begin{table}[H]
  \begin{tabular}{lrrrrrr}
    \toprule
    Size & HTTPS & HTTP over Tor & HTTPS over Tor \\
    \midrule
    1514 & 5,158,795 & 4,753,794 & 2,245,490\\
    652 & 347,365 & 4,452,695 & 3,082,768\\
    66 & 2,954,910 & 4,536,500 & 2,295,206\\
    \bottomrule
  \end{tabular}
  \caption{Summary of packet sizes}
  \label{table:packet_size_summary}
\end{table}

Investigating more closely, by examining individual packet traces some
significant patterns begin to appear. Table \ref{table:packet_sizes} shows the
packet sizes seen for the first 10 packets of a 1\% sample of sessions in each
phase of data captured. The first few packets contain 0 bytes of data, these
are the typical SYN, SYN/ACK and ACK flagged packets that are used to initiate
a TCP/IP connection. Following that only two packet sizes are seen for HTTP
connections 100 and 110. For Tor sessions a range of packet sizes from 131 to
152. This knowledge can be used to build a very rudimentary classification
algorithm to identify Tor traffic, as seen in the pseudo-code below:

\begin{lstlisting}[language=ruby]
if packet[3] > 130 && packet[3] <  153 && packet[5] > 913 && packet[5] < 937
  is_tor = true
else
  is_tor = false
end
\end{lstlisting}

Applying this algorithm to a 10\% sample of each of the packet traces yields
the results as seen in table \ref{table:heuristic-results}.

\begin{table}[H]
  \begin{tabular}{lr}
    \toprule
    Protocol & Identified as Tor\\
    \midrule
    HTTPS & 0.0000\% \\
    HTTP over Tor & 0.9903\% \\
    HTTPS over Tor & 0.9826\% \\
    \bottomrule
  \end{tabular}
  \caption{Results}
  \label{table:heuristic-results}
\end{table}

\input{session-packet-sizes.tex}

\section{Possible Implications of Results}

The research results suggest that the strategies used by anonymous networks to
hide the identity of network participants, may make those anonymous networks
more easy to distinguish from networks and software that do not provide any
anonymity.

Research has shown that the low latency design of Tor means it is vulnerable to
traffic analysis attacks that correlate traffic patterns with users. This
vulnerability is indicative of the subtle amount of overhead incurred when
sending traffic through Tor. This should make it difficult to identify whether a
connection is using Tor VS not using Tor, though it is clearly still possible.
Reducing this overhead further may reduce the success of Tor traffic
identification.

Stronger anonymity providing networks utilize more sophisticated techniques to
hide individual identities such as batching, queuing and normalization. While
they may be more resistant to identity uncovering attacks, this may also make
them more easily identifiable by classification techniques.

\chapter{Conclusion}

\section{Conclusion and Future Research}

This research demonstrates that Tor does have characteristics that make it
distinguishable from regular encrypted traffic. The encryption used by Tor does
not appear to blur the size of communication cells sufficiently to prevent
automated identification of Tor traffic, even with only a few observed packets.
While the scope of this research is limited, it suggests that it may be
possible to build simple software to automatically identify Tor users and block
them from the network.

Further research needs to be conducted with live packet traces from real
participants in the Tor network. Most existing traffic classification research
operates this way, using exact matching techniques to separate traces collected
into treatment and control groups. Real Tor traffic might be captured from
publicly available and co-operating Tor nodes and compared to real encrypted
sessions between well known public HTTPS servers.

Training a classifier against real world traffic will account for the different
and varied nature of packet switching hardware, with different maximum
transmission units, performance capabilities and geographic location.

The heuristic based classifier used in this paper used a single attribute: the
size of individual packets in a stream, to classify with great accuracy. But
other attributes may be considered, the most typical of these being inter
packet arrival time - though this is likely to be more affected by natural
variability.

The encrypted traffic generated in the first phase of the experiment, only
covered a single application and version. It may be possible that other
applications use the same protocol with encryption and have characteristics
similar to that produced by Tor. This would lead to any proposed classifier
generating false positives. Further research should also consider the nature
and characteristics of a wider set of encrypted communications.
